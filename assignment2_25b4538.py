# -*- coding: utf-8 -*-
"""Assignment2_25b4538.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_s_SP-sB3Fn2v0PA6Q2iusgd8YRG4iD9

## WEEK-2 Assignment
Fill the missing places wherever TO DO is mentioned and also understnad what has been done properly


**Also give explanation about each graph and what all you understood about it by adding a text cell below the respective graph**

Do not use Chatgpt . It is a simple assignment. Make a copy of this colab notebook and do your changes and submit it as `Assignment2_yourrollno.ipnyb`
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

TICKERS = ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS"] #you can choose assets of your own wish

df = yf.download(TICKERS, period="3y")
prices = df.xs("Close", axis=1, level=0)

prices = prices.fillna(method="ffill").dropna()
prices.head()

log_returns_hdfc = np.log(prices['HDFCBANK.NS']/prices['HDFCBANK.NS'].shift(1))
log_returns_tcs = np.log(prices['TCS.NS']/prices['TCS.NS'].shift(1))
log_returns_reliance = np.log(prices['RELIANCE.NS']/prices['RELIANCE.NS'].shift(1))
log_returns = pd.DataFrame([log_returns_hdfc,log_returns_reliance,log_returns_tcs])
log_returns = log_returns.T
log_returns=log_returns.dropna()        #TO DO : calculate log return
log_returns.head()

sqrt=np.sqrt
TRADING_DAYS = 252
mu = log_returns.mean()*TRADING_DAYS                      #TO DO : Calculate Expected return (annual)
cov_matrix = log_returns.std()*sqrt(TRADING_DAYS)              #TO DO : Calculate Covariance matrix

mu, cov_matrix,

# step controls how finely we explore the portfolio weight space.
# step = 0.02 means weights change in increments of 2%:
# 0.00, 0.02, 0.04, ..., 1.00
# Smaller step  -> more portfolios -> higher accuracy -> slower computation
# Larger step  -> fewer portfolios -> faster but coarser approximation
step = 0.02  # You can consider some other step sizes too
weights = []   # This list will store all VALID portfolios. Each portfolio is a vector: [w1, w2, w3]


# Loop over possible values of weight for Asset 1
for w1 in np.arange(0, 1 + step, step):
    # For each w1, loop over possible values of weight for Asset 2
    for w2 in np.arange(0, 1 + step, step):
        w3 =1-w1-w2                         # TO DO : What should be w3 in terms of w1 and w2 (Budget constraint)
        if w3>0:                       # TO DO : what should be the condition for the if statement so that it satisfies long-only constraint Change the tru to ypur condition
            weights.append([w1, w2, w3])

weights = np.array(weights)
#TO DO : print the no. of feasible portfolios
print(len(weights))

# Lists to store portfolio returns and volatility
portfolio_returns = []
portfolio_volatility = []


# Loop over every feasible portfolio weight vector
for w in weights:
    ret =(mu.T)@w                    # TO DO : Calculate return of Portfolio
    var = (w.T)@(log_returns.cov())@(w)                        # TO DO : Calculate Volatility

    portfolio_returns.append(ret)
    portfolio_volatility.append(np.sqrt(var))

portfolio_df = pd.DataFrame(weights, columns=["w1", "w2", "w3"])
portfolio_df["Return"] = portfolio_returns
portfolio_df["Volatility"] = portfolio_volatility

portfolio_df.head()
print(log_returns.cov())

#Visualization for Risk Surface
plt.figure(figsize=(8,6))
sc = plt.scatter(
    portfolio_df["w1"],
    portfolio_df["w2"],
    c=portfolio_df["Volatility"],
    cmap="viridis",
    s=10
)

plt.colorbar(sc, label="Portfolio Volatility")
plt.xlabel("Weight of Asset 1")
plt.ylabel("Weight of Asset 2")
plt.title("Portfolio Risk Surface (w₃ = 1 − w₁ − w₂)")
plt.show()

min_var_idx = portfolio_df["Volatility"].idxmin()                         # TO DO : Discover the Minimum Variance Portfolio
min_var_portfolio = portfolio_df.loc[min_var_idx]                   #To Do : Fill this

min_var_portfolio

# Risk-Return for all Portfolios (Visualization)
plt.figure(figsize=(8,6))
plt.scatter(
    portfolio_df["Volatility"],
    portfolio_df["Return"],
    alpha=0.4
)

plt.xlabel("Volatility")
plt.ylabel("Expected Return")
plt.title("Risk–Return Cloud (All Feasible Portfolios)")
plt.show()

# To DO: Study about the red line what is it called and what it signifies
bins = np.linspace(
    portfolio_df["Return"].min(),
    portfolio_df["Return"].max(),
    40
)

frontier_risk = []
frontier_return = []

for i in range(len(bins)-1):
    mask = (portfolio_df["Return"] >= bins[i]) & (portfolio_df["Return"] < bins[i+1])
    subset = portfolio_df[mask]

    if len(subset) > 0:
        min_row = subset.loc[subset["Volatility"].idxmin()]
        frontier_risk.append(min_row["Volatility"])
        frontier_return.append(min_row["Return"])

plt.figure(figsize=(8,6))
plt.scatter(portfolio_df["Volatility"], portfolio_df["Return"], alpha=0.2)
plt.plot(frontier_risk, frontier_return, color="red", linewidth=2)
plt.xlabel("Volatility")
plt.ylabel("Expected Return")
plt.show()

"""The red line is the collection of points which gives a given return with the least possible risk i.e. we make a horizontal line at the desired return and the leftmost point lying on the line represents the portfolio with minimum volatility having that return. But, the red line contains some portfolios which one should not choose since we can get better returns at the same risk."""

# Controlled stress test on diversification
# Increase covariance to simulate higher correlation. This mimics market stress where assets move together
stressed_cov =    log_returns.cov().copy()             # TO DO : Create a copy of the original covariance matrix

for i in range(len(stressed_cov)):
    for j in range(len(stressed_cov)):
        if i != j:
            stressed_cov.iloc[i, j] *= 2    # Can change the factor from 2 to any other no. too. Try chaging to diff values

# List to store portfolio volatility after correlation stress
stressed_volatility = []

for w in weights:
    var =     (w.T)@stressed_cov@w                       #TO DO :  Calculate Portfolio variance under stressed covariance
    stressed_volatility.append(np.sqrt(var))

portfolio_df["Stressed Volatility"] = stressed_volatility

#TO DO : Study this graph. It represents two conditions one with normal corr and one with stressed corr
plt.figure(figsize=(8,6))

plt.scatter(
    portfolio_df["Volatility"],
    portfolio_df["Return"],
    alpha=0.3,
    label="Original"
)

plt.scatter(
    portfolio_df["Stressed Volatility"],
    portfolio_df["Return"],
    alpha=0.3,
    label="Stressed"
)

plt.xlabel("Volatility")
plt.ylabel("Expected Return")
plt.title("Effect of Increased Correlation on Portfolios")
plt.legend()
plt.show()

"""Correlation is a measure of riskiness of the portfolio. Higher correlation between assets means that they move in similar ways in a given period. So, Analysing the impact of stressed correlation on portfolio is important as the correlations may change over time due to many factors. As we can see from the graph, if the correlations are scaled up by two the same returns are expected for a higher amount of risk(volatility)."""

asset_vol = log_returns.std()*sqrt(TRADING_DAYS)
                       # TO DO : Compute individual asset volatility (annualized)

#Visualization
#TO DO : study this graph
plt.figure(figsize=(9,7))

# Portfolios
plt.scatter(portfolio_df["Volatility"], portfolio_df["Return"], alpha=0.15)

# Efficient Frontier
plt.plot(frontier_risk, frontier_return, color="red", linewidth=3)

# Assets
plt.scatter(asset_vol, mu, s=120, color="black")
for asset in mu.index:
    plt.text(asset_vol[asset]*1.01, mu[asset]*1.01, asset)

plt.xlabel("Volatility")
plt.ylabel("Expected Return")
plt.title("Portfolio Geometry & Efficient Frontier")
plt.show()

"""The three black dots represent the portfolios containing the individual stocks.The blue dots represents various portfolios made by combinations of the 3 stocks. The red line is the filtered collection of portfolios from which an investor should choose based on his/her risk appetite and expectation of returns. It is clear that choosing an appropriate combination of the stocks significantly reduces the risk while not effecting the return much."""